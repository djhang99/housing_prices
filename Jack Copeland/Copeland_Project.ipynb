{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Regression Maching Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports (Data and Packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_preprocessing_final import cleaning, dummify, scale_data, ord_encoding, initiate_data\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('./data/Ames_Housing_Price_Data.csv', index_col=0)\n",
    "train_data_linear, train_target_linear, test_data_linear, test_target_linear, train_data_tree, train_target_tree, test_data_tree, test_target_tree = initiate_data(housing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle = pd.read_pickle('lasso_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_linear.drop(['PID'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9373935753763666"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.score(test_data_linear, test_target_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Working on Lasso Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphaRange = np.linspace(0,0.0005,5)\n",
    "params = {'alpha': alphaRange, 'max_iter' : [10000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\jackc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jackc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.073831279823459, tolerance: 0.02087087596564399\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jackc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\jackc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jackc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.8819010276513293, tolerance: 0.020692015524425428\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jackc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\jackc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jackc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.089011571744615, tolerance: 0.020794882482215518\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jackc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\jackc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jackc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.272360236820169, tolerance: 0.020814528489131744\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jackc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:593: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\jackc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jackc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.27367652963922, tolerance: 0.020415073260934502\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Lasso(),\n",
       "             param_grid={'alpha': array([0.      , 0.000125, 0.00025 , 0.000375, 0.0005  ]),\n",
       "                         'max_iter': [10000]},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(lasso, params, scoring = 'r2', cv=5)\n",
    "gs.fit(train_data_linear, train_target_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.000125, 'max_iter': 10000}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9538218820797553"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(train_data_linear, train_target_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9266089895873977"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(test_data_linear, test_target_linear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = gs.predict(test_data_linear)\n",
    "predict = pd.DataFrame(predict)\n",
    "predict.columns = ['Prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ElasticNet.fit of Lasso(alpha=0.000125, max_iter=10000)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sorted(list(zip(gs.best_estimator_.coef_, train_data_linear.columns)), key = lambda t: t[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "for i in range(len(features)):\n",
    "    dict[features[i][1]] = features[i][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish Connection with Tableau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabpy_client\n",
    "from tabpy.tabpy_tools.client import Client\n",
    "\n",
    "\n",
    "def predict_price(_arg1,_arg2,_arg3, _arg4):\n",
    "    scaler = MinMaxScaler()\n",
    "    test_nums = housing[['TotalLivArea', 'LotArea','GarageArea', 'YearBuilt']]\n",
    "    scaler.fit(test_nums)\n",
    "\n",
    "\n",
    "    row = train_data_linear[train_data_linear['PID'] == 1]\n",
    "    row = row.assign(TotalLivArea = _arg1)\n",
    "    row = row.assign(LotArea = _arg2)\n",
    "    row = row.assign(GarageArea = _arg3)\n",
    "    row = row.assign(YearBuilt = _arg4)\n",
    "\n",
    "    row_scale = row[['TotalLivArea', 'LotArea','GarageArea', 'YearBuilt']]\n",
    "    row.drop(columns = row_scale.columns, inplace = True, axis=1)\n",
    "    row_scaled = scaler.transform(row_scale)\n",
    "    row_scaled = pd.DataFrame(row_scaled, columns = row_scale.columns)\n",
    "    row_scaled['PID'] = 1\n",
    "    row = pd.merge(row, row_scaled, on = 'PID')\n",
    "    row.drop(['PID'], axis =1, inplace =True)\n",
    "    price = pickle.predict(row)\n",
    "    price = int(np.exp(price))\n",
    "    return price\n",
    "\n",
    "client = tabpy_client.Client('http://localhost:9004/')\n",
    "client.deploy('predict_price', predict_price, 'predicts price based on inputs', override = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    housing = pd.read_csv('./data/Ames_Housing_Price_Data.csv', index_col=0)\n",
    "\n",
    "    # _arg1 = 'OldTown'\n",
    "    row = housing[housing['PID'] == 1].copy()\n",
    "    row['Neighborhood'] = _arg1\n",
    "\n",
    "    housing.drop(housing[housing['PID'] == 1].index, inplace=True)\n",
    "    housing = housing.append(row)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #### Clean Data #################################################\n",
    "\n",
    "    ## LotFrontage -- replace with mean of the column\n",
    "    housing['LotFrontage'].fillna(value = housing['LotFrontage'].mean(), inplace = True)\n",
    "    housing['GarageYrBlt'].fillna(value = housing['GarageYrBlt'].mean(), inplace=True)\n",
    "\n",
    "    ## Replace Nulls where NA just means that the house does not have the feature\n",
    "\n",
    "    ## Basement metrics\n",
    "    housing['BsmtQual'].fillna(value = 'No_Basement', inplace=True)\n",
    "    housing['BsmtCond'].fillna(value = 'No_Basement', inplace=True)\n",
    "    housing['BsmtExposure'].fillna(value = 'No_Basement', inplace=True)\n",
    "    housing['BsmtFinType1'].fillna(value = 'No_Basement', inplace=True)\n",
    "    housing['BsmtFinType2'].fillna(value = 'No_Basement', inplace=True)\n",
    "\n",
    "    ## Garage Type\n",
    "    housing['GarageType'].fillna(value = 'No_Garage', inplace=True)\n",
    "\n",
    "    housing['GarageFinish'].fillna(value = 'No_Garage', inplace=True)\n",
    "    housing['GarageQual'].fillna(value = 'No_Garage', inplace=True)\n",
    "    housing['GarageCond'].fillna(value = 'No_Garage', inplace=True)\n",
    "\n",
    "    ## Replace other nulls where null just means the feature is not there\n",
    "    housing['FireplaceQu'].fillna(value = 'No_Fireplace', inplace=True)\n",
    "    housing['PoolQC'].fillna(value = 'No_Pool', inplace=True)\n",
    "    housing['Fence'].fillna(value = 'No_Fence', inplace=True)\n",
    "    housing['MiscFeature'].fillna(value = 'No_Misc', inplace=True)\n",
    "    housing['Alley'].fillna(value = 'No_alley', inplace=True)\n",
    "\n",
    "    housing['MasVnrType'].fillna(value = 'None', inplace=True)\n",
    "\n",
    "\n",
    "    ##----------------------------------------------------------------##\n",
    "\n",
    "    ##Replacing nulls with 0s\n",
    "\n",
    "    housing['BsmtFinSF1'].fillna(value = 0, inplace=True)\n",
    "    housing['BsmtFinSF2'].fillna(value = 0, inplace=True)\n",
    "    housing['BsmtUnfSF'].fillna(value = 0, inplace=True)\n",
    "    housing['TotalBsmtSF'].fillna(value = 0, inplace=True)\n",
    "    housing['MasVnrArea'].fillna(value = 0, inplace=True)\n",
    "    housing['BsmtFullBath'].fillna(value = 0, inplace=True)\n",
    "    housing['BsmtHalfBath'].fillna(value = 0, inplace=True)\n",
    "    housing['GarageCars'].fillna(value = 0, inplace=True)\n",
    "    housing['GarageArea'].fillna(value = 0, inplace=True)\n",
    "\n",
    "\n",
    "    ## At this point, only one null value remains in the \"Electric Column\". We will just remove that one row\n",
    "    housing.dropna(axis = 0, inplace = True)\n",
    "\n",
    "\n",
    "    ## Create new variables\n",
    "\n",
    "\n",
    "    ## Add a total baths feature and remove the original columns\n",
    "    housing['TotalBath'] = housing['FullBath'] + (housing['HalfBath']*0.5) + housing['BsmtFullBath'] + (housing['BsmtHalfBath']*0.5)\n",
    "    baths_drop = ['HalfBath', 'FullBath', 'BsmtFullBath', 'BsmtHalfBath']\n",
    "    housing.drop(columns= baths_drop, inplace=True, axis =1)\n",
    "\n",
    "    ## Add ratio for unfinished basement space -- Make sure this is always before \"TotalLivArea\" is created or columns will be dropped\n",
    "    housing['Bsmt_Unfin_Ratio'] = housing['BsmtUnfSF'] / housing['TotalBsmtSF']\n",
    "    housing.drop(columns = 'BsmtUnfSF', axis = 1, inplace = True)\n",
    "\n",
    "    ## Add a total living area feature and remove original columns\n",
    "    housing['TotalLivArea'] = housing['GrLivArea'] + housing['TotalBsmtSF']\n",
    "    liv_drop = ['GrLivArea', 'TotalBsmtSF']\n",
    "    housing.drop(columns = liv_drop, axis = 1, inplace = True)\n",
    "\n",
    "    ## Remove bedrooms from above ground total rooms to avoid multicollinearity\n",
    "    housing['TotRmsAbvGrd'] = housing['TotRmsAbvGrd'] - housing['BedroomAbvGr']\n",
    "\n",
    "\n",
    "    ## Remove unnecessary columns\n",
    "    cols_to_drop = [\n",
    "        '1stFlrSF',\n",
    "        '2ndFlrSF',\n",
    "        'BsmtFinSF1',\n",
    "        'BsmtFinSF2',\n",
    "        'Street',\n",
    "        'Alley',\n",
    "        'Utilities',\n",
    "        'Condition2',\n",
    "        'RoofMatl',\n",
    "        'Heating',\n",
    "        'Electrical',\n",
    "        'LowQualFinSF',\n",
    "        'KitchenAbvGr',\n",
    "        'GarageCars',\n",
    "        'GarageCond',\n",
    "        'PoolArea',\n",
    "        'PoolQC',\n",
    "        'MiscFeature',\n",
    "        'MiscVal',\n",
    "        'SaleType']\n",
    "\n",
    "    housing.drop(columns= cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "    # Grouping all the different irregular lotshapes together as 'IR'\n",
    "    housing.loc[housing.LotShape == 'IR1', 'LotShape'] = 'IR'\n",
    "    housing.loc[housing.LotShape == 'IR2', 'LotShape'] = 'IR'\n",
    "    housing.loc[housing.LotShape == 'IR3', 'LotShape'] = 'IR'\n",
    "\n",
    "    # Grouping all the rare roofstyles together as 'Other'\n",
    "    housing.loc[housing.RoofStyle == 'Gambrel', 'RoofStyle'] = 'Other'\n",
    "    housing.loc[housing.RoofStyle == 'Flat', 'RoofStyle'] = 'Other'\n",
    "    housing.loc[housing.RoofStyle == 'Mansard', 'RoofStyle'] = 'Other'\n",
    "    housing.loc[housing.RoofStyle == 'Shed', 'RoofStyle'] = 'Other'\n",
    "\n",
    "    housing['Bsmt_Unfin_Ratio'].fillna(value = 0, inplace = True)\n",
    "\n",
    "    housing = housing[~housing.PID.isin([904300150, 535383070, 905426030, 528142130])]\n",
    "\n",
    "    housing = housing[housing['SaleCondition'] == 'Normal']\n",
    "\n",
    "    housing = housing.drop_duplicates(subset=['PID'], keep='first', ignore_index=False)\n",
    "\n",
    "    housing = housing.reset_index() #duplicated index values in csv need to reset\n",
    "    housing = housing.drop('index', axis = 1) # drop original index with duplicates\n",
    "    ## Grab objects from dataframe\n",
    "    category = housing.select_dtypes('object')\n",
    "\n",
    "    ##Grab data that is numerical but should be treated as object (i.e. should be dummified)\n",
    "    ## Merge it back into category to be dummified\n",
    "    housing_num2cat = housing[['MSSubClass', 'OverallQual', 'OverallCond', \\\n",
    "                                'MoSold', 'YrSold']]\n",
    "\n",
    "    category = pd.concat([category, housing_num2cat.astype(str)], axis = 1)\n",
    "\n",
    "    ## Dummify variables\n",
    "    cat_dum = pd.get_dummies(category, drop_first = True)\n",
    "\n",
    "    ## Drop objects out of dataframe\n",
    "    drop = list(category.columns)\n",
    "    for column in housing_num2cat.columns:\n",
    "        drop.append(column)\n",
    "    housing.drop(columns = drop, axis = 1, inplace = True)\n",
    "\n",
    "    ## Merge dummified back into original dataframe\n",
    "    housing = pd.concat([housing, cat_dum], axis = 1)\n",
    "\n",
    "\n",
    "    ### Dummifying ###############################################################\n",
    "\n",
    "\n",
    "        ## Train Test Split\n",
    "\n",
    "    train_data_linear, test_data_linear = train_test_split(housing, test_size=0.2, random_state = 0)\n",
    "    train_data_linear = train_data_linear.copy()\n",
    "    test_data_linear = test_data_linear.copy()\n",
    "\n",
    "\n",
    "    scale_trainer = train_data_linear.copy()\n",
    "    scale_trainer = scale_trainer.reset_index() #duplicated index values in csv need to reset\n",
    "    scale_trainer = scale_trainer.drop('index', axis = 1) # drop original index with duplicates\n",
    "    scale_trainer_num = scale_trainer.select_dtypes(['int64', 'float64']) # Select numeric data types\n",
    "    scale_trainer_num = scale_trainer_num.drop(['PID', 'SalePrice'], axis = 1) ## Drop PID and saleprice since they should not be scaled\n",
    "\n",
    "    ## Set up and train the scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(scale_trainer_num)\n",
    "\n",
    "    housing = housing.reset_index() #duplicated index values in csv need to reset\n",
    "    housing = housing.drop('index', axis = 1) # drop original index with duplicates\n",
    "    dataframe_num = housing[['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',\n",
    "                            'BedroomAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt',\n",
    "                            'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
    "                            'ScreenPorch', 'Bsmt_Unfin_Ratio', 'TotalLivArea', 'TotalBath']] # Select columns that were used to train the scaler\n",
    "\n",
    "    ## Drop the original columns from the main dataframe\n",
    "    housing.drop(columns = dataframe_num.columns, axis = 1, inplace =True)\n",
    "\n",
    "    ## Scale the new columns and make dataframe\n",
    "    num_scaled = scaler.transform(dataframe_num)\n",
    "    dataframe_num_scaled = pd.DataFrame(num_scaled, columns = dataframe_num.columns)\n",
    "\n",
    "    ## Merge back into old dataframe\n",
    "    housing = pd.concat([housing, dataframe_num_scaled], axis=1)\n",
    "\n",
    "    ## Separate out target\n",
    "    target = np.log(housing['SalePrice'])\n",
    "    housing.drop('SalePrice', axis=1, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "    ## Set up linear training and testing data\n",
    "    # train_data_linear, train_target_linear = scale_data(train_data_linear, scaler)\n",
    "    # test_data_linear, test_target_linear = scale_data(test_data_linear, scaler)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## Set up train test data\n",
    "    ## note, random seed is set so that PID == 1 will always be in test daata\n",
    "    # train_data_linear, train_target_linear, test_data_linear, test_target_linear, train_data_tree, train_target_tree, test_data_tree, test_target_tree = initiate_data(housing)\n",
    "\n",
    "    ## use the model to predict on the test set and then pull out where PID == 1\n",
    "\n",
    "    train_data_linear = train_data_linear[train_data_linear['PID'] == 1]\n",
    "    train_data_linear.drop(['PID'] , axis =1, inplace =True)\n",
    "    predict = pickle.predict(train_data_linear)\n",
    "    predict = pd.DataFrame(predict)\n",
    "    predict.columns = ['Prediction']\n",
    "    z = np.exp(predict['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_for_tableau(_arg1):\n",
    "    from data_preprocessing_final import initiate_data\n",
    "    housing = pd.read_csv('./data/Ames_Housing_Price_Data.csv', index_col=0)\n",
    "\n",
    "    # _arg1 = 'OldTown'\n",
    "    row = housing[housing['PID'] == 1].copy()\n",
    "    row['Neighborhood'] = _arg1\n",
    "\n",
    "    housing.drop(housing[housing['PID'] == 1].index, inplace=True)\n",
    "    housing = housing.append(row)\n",
    "\n",
    "    ## Set up train test data\n",
    "    ## note, random seed is set so that PID == 1 will always be in test daata\n",
    "    train_data_linear, train_target_linear, test_data_linear, test_target_linear, train_data_tree, train_target_tree, test_data_tree, test_target_tree = initiate_data(housing)\n",
    "\n",
    "    ## use the model to predict on the test set and then pull out where PID == 1\n",
    "\n",
    "    train_data_linear = train_data_linear[train_data_linear['PID'] == 1]\n",
    "    train_data_linear.drop(['PID'] , axis =1, inplace =True)\n",
    "    predict = pickle.predict(train_data_linear)\n",
    "    predict = pd.DataFrame(predict)\n",
    "    predict.columns = ['Prediction']\n",
    "    z = np.exp(predict['Prediction'])\n",
    "    return z.iloc[0]\n",
    "\n",
    "client = tabpy_client.Client('http://localhost:9004/')\n",
    "client.deploy('predict_for_tableau', predict_for_tableau, 'predicts price based on inputs', override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tabpy_client.Client('http://localhost:9004/')\n",
    "client.deploy('predict_for_tableau', predict_for_tableau, 'predicts price based on inputs', override = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153712.97072623216"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predict_for_tableau('BrkSide')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "_arg1 = 1000\n",
    "_arg2 = 2000\n",
    "_arg3 = 1000\n",
    "_arg4 = 2005\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "test_nums = housing[['TotalLivArea', 'LotArea','GarageArea', 'YearBuilt']]\n",
    "scaler.fit(test_nums)\n",
    "\n",
    "row = train_data_linear[train_data_linear['PID'] == 1]\n",
    "row = row.assign(TotalLivArea = _arg1)\n",
    "row = row.assign(LotArea= _arg2)\n",
    "row = row.assign(GarageArea = _arg3)\n",
    "row = row.assign(YearBuilt = _arg4)\n",
    "\n",
    "row_scale = row[['TotalLivArea', 'LotArea','GarageArea', 'YearBuilt']]\n",
    "row.drop(columns = row_scale.columns, inplace = True, axis=1)\n",
    "row_scaled = scaler.transform(row_scale)\n",
    "row_scaled = pd.DataFrame(row_scaled, columns = row_scale.columns)\n",
    "row_scaled['PID'] = 1\n",
    "row = pd.merge(row, row_scaled, on = 'PID')\n",
    "\n",
    "row.drop(['PID'], axis =1, inplace =True)\n",
    "price = pickle.predict(row)\n",
    "price = int(np.exp(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65634"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>PID</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Pct_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$204,267.84</td>\n",
       "      <td>907181100</td>\n",
       "      <td>$192,000.00</td>\n",
       "      <td>$6.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$159,926.91</td>\n",
       "      <td>531452070</td>\n",
       "      <td>$145,000.00</td>\n",
       "      <td>$10.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$157,032.98</td>\n",
       "      <td>910204050</td>\n",
       "      <td>$123,000.00</td>\n",
       "      <td>$27.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$271,266.09</td>\n",
       "      <td>924151040</td>\n",
       "      <td>$285,000.00</td>\n",
       "      <td>$-4.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$150,359.73</td>\n",
       "      <td>923277040</td>\n",
       "      <td>$138,000.00</td>\n",
       "      <td>$8.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>$154,205.68</td>\n",
       "      <td>908152110</td>\n",
       "      <td>$160,500.00</td>\n",
       "      <td>$-3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>$130,812.19</td>\n",
       "      <td>902427180</td>\n",
       "      <td>$110,000.00</td>\n",
       "      <td>$18.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>$270,753.79</td>\n",
       "      <td>528180080</td>\n",
       "      <td>$282,500.00</td>\n",
       "      <td>$-4.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>$136,196.61</td>\n",
       "      <td>534275170</td>\n",
       "      <td>$151,500.00</td>\n",
       "      <td>$-10.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>$283,533.96</td>\n",
       "      <td>528344060</td>\n",
       "      <td>$280,000.00</td>\n",
       "      <td>$1.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>482 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prediction        PID   SalePrice  Pct_diff\n",
       "0   $204,267.84  907181100 $192,000.00     $6.39\n",
       "1   $159,926.91  531452070 $145,000.00    $10.29\n",
       "2   $157,032.98  910204050 $123,000.00    $27.67\n",
       "3   $271,266.09  924151040 $285,000.00    $-4.82\n",
       "4   $150,359.73  923277040 $138,000.00     $8.96\n",
       "..          ...        ...         ...       ...\n",
       "477 $154,205.68  908152110 $160,500.00    $-3.92\n",
       "478 $130,812.19  902427180 $110,000.00    $18.92\n",
       "479 $270,753.79  528180080 $282,500.00    $-4.16\n",
       "480 $136,196.61  534275170 $151,500.00   $-10.10\n",
       "481 $283,533.96  528344060 $280,000.00     $1.26\n",
       "\n",
       "[482 rows x 4 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = pd.concat([predict, test_data_linear, test_target_linear], axis =1)\n",
    "pd.options.display.float_format = '${:,.2f}'.format\n",
    "final['SalePrice'] = np.exp(final['SalePrice'])\n",
    "final['Prediction'] = np.exp(final['Prediction'])\n",
    "final['Pct_diff'] = ((final['Prediction'] - final['SalePrice'])/ final['SalePrice'])*100\n",
    "final[['Prediction', 'PID','SalePrice', 'Pct_diff']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rf_model = RandomForestRegressor(random_state=0)\n",
    "# # rf_model.fit(train_data_tree, train_target_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set MSE is 0.002\n",
      "Train set R2 is 0.987\n",
      "Test set MSE is 0.014\n",
      "Test set R2 is 0.900\n"
     ]
    }
   ],
   "source": [
    "# train_preds = rf_model.predict(train_data_tree)\n",
    "# train_mse = mean_squared_error(train_target_tree, train_preds)\n",
    "# print('Train set MSE is {:.3f}'.format(train_mse))\n",
    "# print('Train set R2 is {:.3f}'.format(rf_model.score(train_data_tree, train_target_tree)))\n",
    "\n",
    "# train_preds_test = rf_model.predict(test_data_tree)\n",
    "# test_mse = mean_squared_error(test_target_tree, train_preds_test)\n",
    "# print('Test set MSE is {:.3f}'.format(test_mse))\n",
    "# print('Test set R2 is {:.3f}'.format(rf_model.score(test_data_tree, test_target_tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted = pd.DataFrame(train_preds_test, columns = ['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_tree = pd.concat([test_data_tree, predicted, test_target_tree], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_tree['SalePrice'] = np.exp(final_tree['SalePrice'])\n",
    "# final_tree['Prediction'] = np.exp(final_tree['Prediction'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TotalLivArea', 0.611769695940967),\n",
       " ('OverallQual', 0.08686860517170654),\n",
       " ('YearBuilt', 0.05478411049723338),\n",
       " ('ExterQual', 0.049732995132640796),\n",
       " ('GarageArea', 0.033503359751477224),\n",
       " ('LotArea', 0.01584924789713022),\n",
       " ('YearRemodAdd', 0.014954010733209075),\n",
       " ('OverallCond', 0.01378381832177892),\n",
       " ('GarageYrBlt', 0.009841980604745044),\n",
       " ('Fireplaces', 0.00858066722733795),\n",
       " ('Bsmt_Unfin_Ratio', 0.008524948559485133),\n",
       " ('KitchenQual', 0.007377373224292001),\n",
       " ('PID', 0.0066638062850456125),\n",
       " ('LotFrontage', 0.005476215459166589),\n",
       " ('Neighborhood', 0.004804537389080459),\n",
       " ('BsmtFinType1', 0.004671099787307095),\n",
       " ('GarageType', 0.0040362385248738355),\n",
       " ('MSSubClass', 0.004009441058954551),\n",
       " ('OpenPorchSF', 0.0038353831218833796),\n",
       " ('CentralAir', 0.0034308679995132658),\n",
       " ('MasVnrArea', 0.003281391509908226),\n",
       " ('MSZoning', 0.0030934202532820164),\n",
       " ('WoodDeckSF', 0.002615876766571731),\n",
       " ('MoSold', 0.0026002048637404837),\n",
       " ('EnclosedPorch', 0.0024281681202639863),\n",
       " ('BsmtQual', 0.0022498547293096686),\n",
       " ('PavedDrive', 0.0017897360765342229),\n",
       " ('Exterior2nd', 0.0017884314448188532),\n",
       " ('YrSold', 0.0017004589642014435),\n",
       " ('TotRmsAbvGrd', 0.0016950630354934432),\n",
       " ('BedroomAbvGr', 0.0016925787734640156),\n",
       " ('HouseStyle', 0.0016309739405735953),\n",
       " ('HeatingQC', 0.0016023044418268806),\n",
       " ('Exterior1st', 0.0015409506624618468),\n",
       " ('FireplaceQu', 0.0014426289907287628),\n",
       " ('BldgType', 0.001412564018458493),\n",
       " ('Condition1', 0.001291219755888969),\n",
       " ('LandContour', 0.001281205711673015),\n",
       " ('Functional', 0.0012637904658004946),\n",
       " ('RoofStyle', 0.0012105228785506952),\n",
       " ('GarageFinish', 0.0010845709982900099),\n",
       " ('BsmtExposure', 0.0010809616888953612),\n",
       " ('ExterCond', 0.000986654442348672),\n",
       " ('Foundation', 0.0008181897850172646),\n",
       " ('GarageQual', 0.0007666084615027086),\n",
       " ('BsmtCond', 0.0007509006448235793),\n",
       " ('ScreenPorch', 0.0007193811534902733),\n",
       " ('Fence', 0.0006867344540242103),\n",
       " ('LotConfig', 0.0006744629690918775),\n",
       " ('LotShape', 0.0006665997066992729),\n",
       " ('BsmtFinType2', 0.0005771943708851823),\n",
       " ('LandSlope', 0.0005427562694095757),\n",
       " ('MasVnrType', 0.0004968458513767149),\n",
       " ('3SsnPorch', 3.839111276645407e-05),\n",
       " ('SaleCondition', 0.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Look at which features had the most important coefficients \n",
    "# sorted(zip(train_data_tree.columns, rf_model.feature_importances_), key = lambda t: t[1], reverse=True)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0361ced4ee9008cee796c675e99fc9755dfaef9b8a7e8c7e0212b1562f6bd272"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
